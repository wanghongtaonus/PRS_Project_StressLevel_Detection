{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d11e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "#from google.colab.patches import cv2_imshow\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b6f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996f0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seq():\n",
    "    global seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9267f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg13_model(n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(64, 64, 1), padding='same', activation='relu',\n",
    "                     kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80aeb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg13_model(8)\n",
    "model.load_weights('./data/model_40-0.80.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34983134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffemodel ' ./data/MobileNetSSD_deploy.caffemodel ' loaded\n"
     ]
    }
   ],
   "source": [
    "classNames      = {0: 'no_face',\n",
    "                   1: 'face'}\n",
    "\n",
    "prototxt        = './data/MobileNetSSD_deploy.prototxt'\n",
    "caffemodel      = './data/MobileNetSSD_deploy.caffemodel'\n",
    "#net             = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)\n",
    "net             = cv2.dnn.readNetFromCaffe(\"./data/deploy.prototxt\",\"./data/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "print(\"caffemodel '\", caffemodel, \"' loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6322b0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videopath       = './data/test.mp4'\n",
    "emotion_dict = {0: \"neutral\", 1: \"happiness\", 2: \"surprise\", 3: \"sadness\", 4: \"anger\", 5: \"disgust\", 6: \"fear\", 7: \"contempt\"}\n",
    "video           = cv2.VideoCapture(videopath)\n",
    "# video           = cv2.VideoCapture(0)\n",
    "scoreThres      = 0.3\n",
    "W               = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H               = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "strat_time = time.time()\n",
    "count = 0\n",
    "e_que = [[[],[]],[[],[]],[[],[]],[[],[]]]\n",
    "r_list = [[],[],[],[]]\n",
    "while True: \n",
    "    count += 1\n",
    "    calc_ex = 0\n",
    "    (grabbed,frame) = video.read()\n",
    "    strat_time = time.time()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    output = frame\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,(300, 300), (104.0, 177.0, 123.0))\n",
    "    rows = blob.shape[2]\n",
    "    cols = blob.shape[3]\n",
    "    net.setInput(blob)\n",
    "    pred = net.forward()\n",
    "    numOfObjects= pred.shape[2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if(count % 25 == 0):\n",
    "        c_t = int(count / 25)\n",
    "        calc_ex = 1\n",
    "    for i in range(numOfObjects):\n",
    "        confidence = pred[0, 0, i, 2]\n",
    "        if confidence > scoreThres:\n",
    "            classId = int(pred[0, 0, i, 1])\n",
    "            x1 = int(pred[0, 0, i, 3] * cols) \n",
    "            y1 = int(pred[0, 0, i, 4] * rows)\n",
    "            x2 = int(pred[0, 0, i, 5] * cols)\n",
    "            y2 = int(pred[0, 0, i, 6] * rows)\n",
    "            hFactor = H/300.0 \n",
    "            wFactor = W/300.0\n",
    "            x1 = int(wFactor*x1) \n",
    "            y1 = int(hFactor*y1)\n",
    "            x2 = int(wFactor*x2)\n",
    "            y2 = int(hFactor*y2)\n",
    "            x = x1\n",
    "            y = y1\n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            #expression detection\n",
    "            p_id = 0\n",
    "            c_x = (x1 + x2)/2\n",
    "            c_y = (y1 + y2)/2\n",
    "            if(c_x > W/2):\n",
    "                if(c_y > H/2):\n",
    "                    p_id = 3\n",
    "                else:\n",
    "                    p_id = 1\n",
    "            else:\n",
    "                if(c_y > H/2):\n",
    "                    p_id = 2\n",
    "                else:\n",
    "                    p_id = 0\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            cropped_img=cv2.resize(roi_gray,(64,64), interpolation=cv2.INTER_LINEAR)\n",
    "            input_data=np.array(cropped_img)\n",
    "            input_data = input_data.reshape(-1, 64, 64, 1)\n",
    "            pre_m = model(input_data,training = False)\n",
    "            prediction = np.array(pre_m)\n",
    "            #prediction = model.predict(input_data)\n",
    "            maxindex1 = int(np.argmax(prediction))\n",
    "            promax1 = prediction[0,maxindex1]\n",
    "            r_list[p_id].append(maxindex1)\n",
    "            if(calc_ex == 1):\n",
    "                if(len(r_list[p_id]) > 0):\n",
    "                    num_temp = np.argmax(np.bincount(r_list[p_id]))\n",
    "                    e_que[p_id][0].append(c_t)\n",
    "                    e_que[p_id][1].append(num_temp)\n",
    "                    r_list[p_id] = []\n",
    "            cv2.putText(output, str(p_id)+\":\"+ emotion_dict[maxindex1] + \"{:.2f}\".format(promax1), (x-1, y+30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            ####\n",
    "            txtlbl = \"{} : {:.2f}\".format(classNames[classId],confidence)\n",
    "            txtsize = cv2.getTextSize(txtlbl,\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    0.5,\n",
    "                                    1)\n",
    "            bsize = txtsize[0]\n",
    "            bsline = txtsize[1]\n",
    "            cv2.rectangle(output, (x,y),(x+w,y+h),(0, 255, 0),2)\n",
    "    tt = 1 / (time.time() - strat_time)\n",
    "    cv2.putText(output,\n",
    "                    \"FPS:\" + str(tt),\n",
    "                    (70,40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (0, 0, 0),\n",
    "                    1,\n",
    "                    cv2.LINE_AA)\n",
    "    cv2.imshow(\"SSD detection\",output)\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc035d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183a9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_level = {0: \"HS\", 1: \"LS\", 2: \"N\", 3: \"LH\", 4: \"HH\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6225c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_tostress = {0: 2, 1: 3, 2: 4, 3: 1, 4: 0, 5: 1, 6: 0, 7: 1}\n",
    "#emotion_dict = {0: \"neutral\", 1: \"happiness\", 2: \"surprise\", 3: \"sadness\", 4: \"anger\", 5: \"disgust\", 6: \"fear\", 7: \"contempt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35cac9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in range(4):\n",
    "#     for state in range(len(e_que[id][1])):\n",
    "#         e_que[id][1][state] = emotion_tostress[e_que[id][1][state]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0b2c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_que[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1163076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    " \n",
    "n_states = 5\n",
    " \n",
    "start_probability = np.array([0.1, 0.1, 0.6, 0.1, 0.1])\n",
    " \n",
    "transition_probability = np.array([  #  HH   LH   N    LS   HS\n",
    "  [0.2, 0.4, 0.2, 0.1, 0.1],\n",
    "  [0.2, 0.4, 0.2, 0.1, 0.1],\n",
    "  [0.1, 0.2, 0.4, 0.2, 0.1],\n",
    "  [0.1, 0.1, 0.2, 0.4, 0.2],\n",
    "  [0.1, 0.1, 0.2, 0.4, 0.2]\n",
    "])\n",
    "\n",
    "emission_probability = np.array([     #{0: \"neutral\", 1: \"happiness\", 2: \"surprise\", 3: \"sadness\", 4: \"anger\", 5: \"disgust\", 6: \"fear\", 7: \"contempt\"}\n",
    "  [0.1, 0.3, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0],#HH\n",
    "  [0.2, 0.6, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],#LH\n",
    "  [0.4, 0.15, 0.05, 0.15, 0.05, 0.05, 0.05, 0.1],#N\n",
    "  [0.1, 0.0, 0.0, 0.3, 0.1, 0.1, 0.1, 0.3],#LS\n",
    "  [0.1, 0.0, 0.0, 0.15, 0.2, 0.2, 0.2, 0.15] #HS\n",
    "])\n",
    " \n",
    "hmmmodel = hmm.MultinomialHMM(n_components=n_states)\n",
    "hmmmodel.startprob_=start_probability\n",
    "hmmmodel.transmat_=transition_probability\n",
    "hmmmodel.emissionprob_=emission_probability\n",
    " \n",
    "seen = np.array([e_que[1][1]]).T\n",
    "print(hmmmodel.predict(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "008e3dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "seen = []\n",
    "result = []\n",
    "for id in range(4):\n",
    "    # print(e_que[id][1])\n",
    "    seen.append([e_que[id][1]])\n",
    "\n",
    "\n",
    "for i in range(len(seen)):\n",
    "    # print(hmmmodel.predict(np.array(seen[i]).T))\n",
    "    result.append(hmmmodel.predict(np.array(seen[i]).T))\n",
    "result\n",
    "\n",
    "#represent stress\n",
    "result_list=list(result)\n",
    "stress=[]\n",
    "for id in range(len(result_list)):\n",
    "    print(id)\n",
    "    stress_id=[]\n",
    "    for i in range(len(result_list[id])):\n",
    "        \n",
    "        print(stress_level[result_list[id][i]])\n",
    "        stress_id.append(stress_level[result_list[id][i]])\n",
    "    stress.append(stress_id)\n",
    "stress\n",
    "plt.figure()\n",
    "for id in range(4):\n",
    "    \n",
    "    plt.subplot(2,2,id+1)\n",
    "    plt.plot(e_que[id][0], stress[id])\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"stress_level\")\n",
    "    plt.title(\"id:\"+str(id))\n",
    "    y_major_locator=MultipleLocator(1)\n",
    "    ax=plt.gca()\n",
    "    ax.yaxis.set_major_locator(y_major_locator)\n",
    "    plt.ylim(-0.5,4)\n",
    "# plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "# fig.tight_layout()\n",
    "plt.subplots_adjust(wspace =1,hspace =1)\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
